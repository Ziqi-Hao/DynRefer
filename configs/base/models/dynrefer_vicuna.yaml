model:
  arch: dynrefer_vicuna

  num_views: 3

  # pretrained weights
  pretrained: "/home/ZhaoYuzhong/zyz/code/Reem/ckpts//blip2/blip2_pretrained_vicuna7b.pth"
  finetune_llm: False

  # contextual visual embedding
  vit_model: "eva_clip_g"
  img_size: 224
  drop_path_rate: 0
  use_grad_checkpoint: False
  vit_precision: "fp16"
  freeze_vit: True

  # tagging head
  tag_bert_config: "dynrefer/models/tagging_heads/tag_bert_config.json"
  tag_list: "dynrefer/common/tagging/ram_tag_list.txt"

  # align network
  num_query_token: 32

  # large language model
  llm_model: "/home/ZhaoYuzhong/zyz/code/Reem/ckpts//vicuna-v1.5-7b"

#  # inference
  tag_thr: 0.7
  first_word_control: False
  apply_lemmatizer: False
  max_txt_len: 32
  num_return_sequences: 1
  do_sample: False
  num_beams: 2
  max_new_tokens: 20
  min_length: 1
  length_penalty: 0
  repetition_penalty: 1.5
  top_p: 0.9
  temperature: 1